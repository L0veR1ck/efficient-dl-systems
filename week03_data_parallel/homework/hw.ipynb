{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a38f1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1,2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b28e1084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb 15 22:58:34 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.28.03              Driver Version: 560.28.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A4000               Off |   00000000:3B:00.0 Off |                  Off |\n",
      "| 54%   72C    P2            127W /  140W |    4565MiB /  16376MiB |     62%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA RTX A4000               Off |   00000000:3C:00.0 Off |                  Off |\n",
      "| 41%   26C    P8             12W /  140W |       4MiB /  16376MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA RTX A4000               Off |   00000000:5E:00.0 Off |                  Off |\n",
      "| 41%   26C    P8             12W /  140W |       4MiB /  16376MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA RTX A4000               Off |   00000000:5F:00.0 Off |                  Off |\n",
      "| 41%   28C    P8             14W /  140W |       4MiB /  16376MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   4  NVIDIA RTX A4000               Off |   00000000:AF:00.0 Off |                  Off |\n",
      "| 47%   66C    P2            109W /  140W |   12200MiB /  16376MiB |     80%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   5  NVIDIA RTX A4000               Off |   00000000:B0:00.0 Off |                  Off |\n",
      "| 50%   70C    P2            133W /  140W |   12194MiB /  16376MiB |     81%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   6  NVIDIA RTX A4000               Off |   00000000:D8:00.0 Off |                  Off |\n",
      "| 50%   66C    P2            122W /  140W |   12194MiB /  16376MiB |     71%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   7  NVIDIA RTX A4000               Off |   00000000:D9:00.0 Off |                  Off |\n",
      "| 52%   67C    P2            132W /  140W |   12194MiB /  16376MiB |    100%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A   3073465      C   ...ukovda/.conda/envs/effdl/bin/python       2322MiB |\n",
      "|    0   N/A  N/A   3709551      C   python                                       2228MiB |\n",
      "|    4   N/A  N/A   1918082      C   ./venv/bin/python                            4060MiB |\n",
      "|    4   N/A  N/A   1918091      C   ./venv/bin/python                            4060MiB |\n",
      "|    4   N/A  N/A   1918099      C   ./venv/bin/python                            4060MiB |\n",
      "|    5   N/A  N/A   1918084      C   ./venv/bin/python                            4058MiB |\n",
      "|    5   N/A  N/A   1918093      C   ./venv/bin/python                            4058MiB |\n",
      "|    5   N/A  N/A   1918101      C   ./venv/bin/python                            4058MiB |\n",
      "|    6   N/A  N/A   1918086      C   ./venv/bin/python                            4058MiB |\n",
      "|    6   N/A  N/A   1918095      C   ./venv/bin/python                            4058MiB |\n",
      "|    6   N/A  N/A   1918103      C   ./venv/bin/python                            4058MiB |\n",
      "|    7   N/A  N/A   1918088      C   ./venv/bin/python                            4058MiB |\n",
      "|    7   N/A  N/A   1918097      C   ./venv/bin/python                            4058MiB |\n",
      "|    7   N/A  N/A   1918104      C   ./venv/bin/python                            4058MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52756a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0215 22:41:09.208000 140528952899392 torch/distributed/run.py:779] \n",
      "W0215 22:41:09.208000 140528952899392 torch/distributed/run.py:779] *****************************************\n",
      "W0215 22:41:09.208000 140528952899392 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0215 22:41:09.208000 140528952899392 torch/distributed/run.py:779] *****************************************\n",
      "Process 0\n",
      "Process 1\n",
      "Process 2\n",
      "Process 2\n",
      "Process 1\n",
      "Process 0\n",
      "---\n",
      "Process 0\n",
      "Process 1\n",
      "Process 2\n",
      "Process 2\n",
      "Process 1\n",
      "Process 0\n",
      "---\n",
      "Process 0\n",
      "Process 1\n",
      "Process 2\n",
      "Process 2\n",
      "Process 1\n",
      "Process 0\n",
      "---\n",
      "Process 0\n",
      "Process 1\n",
      "Process 2\n",
      "Process 2\n",
      "Process 1\n",
      "Process 0\n",
      "---\n",
      "Process 0\n",
      "Process 1\n",
      "Process 2\n",
      "Process 2\n",
      "Process 1\n",
      "Process 0\n",
      "---\n",
      "Process 0\n",
      "Process 1\n",
      "Process 2\n",
      "Process 2\n",
      "Process 1\n",
      "Process 0\n",
      "---\n",
      "Process 0\n",
      "Process 1\n",
      "Process 2\n",
      "Process 2\n",
      "Process 1\n",
      "Process 0\n",
      "---\n",
      "Process 0\n",
      "Process 1\n",
      "Process 2\n",
      "Process 2\n",
      "Process 1\n",
      "Process 0\n",
      "---\n",
      "Process 0\n",
      "Process 1\n",
      "Process 2\n",
      "Process 2\n",
      "Process 1\n",
      "Process 0\n",
      "---\n",
      "Process 0\n",
      "Process 1\n",
      "Process 2\n",
      "Process 2\n",
      "Process 1\n",
      "Process 0\n"
     ]
    }
   ],
   "source": [
    "!torchrun --nproc_per_node 3 sequential_print.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b76d9434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.9, pytest-8.3.4, pluggy-1.6.0\n",
      "rootdir: /home/pliskovskijla/efficient-dl-systems/week03_data_parallel\n",
      "configfile: pyproject.toml\n",
      "plugins: anyio-4.12.1\n",
      "collected 16 items                                                             \u001b[0m\u001b[1m\n",
      "\n",
      "test_syncbn.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                          [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================== \u001b[32m\u001b[1m16 passed\u001b[0m\u001b[32m in 116.86s (0:01:56)\u001b[0m\u001b[32m ========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_syncbn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5aa5a417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0215 23:10:51.299000 140144078358336 torch/distributed/run.py:779] \n",
      "W0215 23:10:51.299000 140144078358336 torch/distributed/run.py:779] *****************************************\n",
      "W0215 23:10:51.299000 140144078358336 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0215 23:10:51.299000 140144078358336 torch/distributed/run.py:779] *****************************************\n",
      "Custom SyncBatchNorm: 2.147 ms | 0.03 MB\n",
      "PyTorch SyncBatchNorm: 2.174 ms | 0.02 MB\n",
      "Speedup: 1.01x\n",
      "Memory reduction: -23.4%\n"
     ]
    }
   ],
   "source": [
    "!torchrun --nproc_per_node=2 bench_syncbn.py --hid_dim 128 --batch_size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "418ba0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0215 23:11:02.649000 140652115547968 torch/distributed/run.py:779] \n",
      "W0215 23:11:02.649000 140652115547968 torch/distributed/run.py:779] *****************************************\n",
      "W0215 23:11:02.649000 140652115547968 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0215 23:11:02.649000 140652115547968 torch/distributed/run.py:779] *****************************************\n",
      "Custom SyncBatchNorm: 2.186 ms | 0.06 MB\n",
      "PyTorch SyncBatchNorm: 2.140 ms | 0.04 MB\n",
      "Speedup: 0.98x\n",
      "Memory reduction: -28.1%\n"
     ]
    }
   ],
   "source": [
    "!torchrun --nproc_per_node=2 bench_syncbn.py --hid_dim 256 --batch_size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54af8cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0215 23:11:13.887000 140178518349632 torch/distributed/run.py:779] \n",
      "W0215 23:11:13.887000 140178518349632 torch/distributed/run.py:779] *****************************************\n",
      "W0215 23:11:13.887000 140178518349632 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0215 23:11:13.887000 140178518349632 torch/distributed/run.py:779] *****************************************\n",
      "Custom SyncBatchNorm: 2.309 ms | 0.11 MB\n",
      "PyTorch SyncBatchNorm: 2.213 ms | 0.08 MB\n",
      "Speedup: 0.96x\n",
      "Memory reduction: -30.6%\n"
     ]
    }
   ],
   "source": [
    "!torchrun --nproc_per_node=2 bench_syncbn.py --hid_dim 512 --batch_size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "170a4083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0215 23:11:25.464000 140268721301312 torch/distributed/run.py:779] \n",
      "W0215 23:11:25.464000 140268721301312 torch/distributed/run.py:779] *****************************************\n",
      "W0215 23:11:25.464000 140268721301312 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0215 23:11:25.464000 140268721301312 torch/distributed/run.py:779] *****************************************\n",
      "Custom SyncBatchNorm: 2.252 ms | 0.22 MB\n",
      "PyTorch SyncBatchNorm: 2.049 ms | 0.17 MB\n",
      "Speedup: 0.91x\n",
      "Memory reduction: -32.0%\n"
     ]
    }
   ],
   "source": [
    "!torchrun --nproc_per_node=2 bench_syncbn.py --hid_dim 1024 --batch_size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e6d2eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0215 23:11:37.064000 140555815249728 torch/distributed/run.py:779] \n",
      "W0215 23:11:37.064000 140555815249728 torch/distributed/run.py:779] *****************************************\n",
      "W0215 23:11:37.064000 140555815249728 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0215 23:11:37.064000 140555815249728 torch/distributed/run.py:779] *****************************************\n",
      "Custom SyncBatchNorm: 2.347 ms | 0.05 MB\n",
      "PyTorch SyncBatchNorm: 2.288 ms | 0.04 MB\n",
      "Speedup: 0.97x\n",
      "Memory reduction: -34.2%\n"
     ]
    }
   ],
   "source": [
    "!torchrun --nproc_per_node=2 bench_syncbn.py --hid_dim 128 --batch_size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c821102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0215 23:11:48.438000 140556370569024 torch/distributed/run.py:779] \n",
      "W0215 23:11:48.438000 140556370569024 torch/distributed/run.py:779] *****************************************\n",
      "W0215 23:11:48.438000 140556370569024 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0215 23:11:48.438000 140556370569024 torch/distributed/run.py:779] *****************************************\n",
      "Custom SyncBatchNorm: 2.019 ms | 0.10 MB\n",
      "PyTorch SyncBatchNorm: 2.291 ms | 0.07 MB\n",
      "Speedup: 1.13x\n",
      "Memory reduction: -37.3%\n"
     ]
    }
   ],
   "source": [
    "!torchrun --nproc_per_node=2 bench_syncbn.py --hid_dim 256 --batch_size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "615c83c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0215 23:11:59.283000 139807674980160 torch/distributed/run.py:779] \n",
      "W0215 23:11:59.283000 139807674980160 torch/distributed/run.py:779] *****************************************\n",
      "W0215 23:11:59.283000 139807674980160 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0215 23:11:59.283000 139807674980160 torch/distributed/run.py:779] *****************************************\n",
      "Custom SyncBatchNorm: 2.282 ms | 0.20 MB\n",
      "PyTorch SyncBatchNorm: 2.070 ms | 0.15 MB\n",
      "Speedup: 0.91x\n",
      "Memory reduction: -38.9%\n"
     ]
    }
   ],
   "source": [
    "!torchrun --nproc_per_node=2 bench_syncbn.py --hid_dim 512 --batch_size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e4c9afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0215 23:12:10.749000 140129617508160 torch/distributed/run.py:779] \n",
      "W0215 23:12:10.749000 140129617508160 torch/distributed/run.py:779] *****************************************\n",
      "W0215 23:12:10.749000 140129617508160 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0215 23:12:10.749000 140129617508160 torch/distributed/run.py:779] *****************************************\n",
      "Custom SyncBatchNorm: 2.329 ms | 0.41 MB\n",
      "PyTorch SyncBatchNorm: 2.124 ms | 0.29 MB\n",
      "Speedup: 0.91x\n",
      "Memory reduction: -39.7%\n"
     ]
    }
   ],
   "source": [
    "!torchrun --nproc_per_node=2 bench_syncbn.py --hid_dim 1024 --batch_size 64"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
